{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3c60d-d491-49a4-b5f1-09ee60479b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 1. IMPORT LIBRARIES AND SET UP ENVIRONMENT\n",
    "# ============================================================================\n",
    "\n",
    "# Standard scientific computing libraries\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Scipy for signal processing and interpolation\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Custom utility modules for neural data analysis\n",
    "from utils.loss import PoissonBPSAggregator\n",
    "from utils.modules import SplitRelu, NonparametricReadout\n",
    "from utils.datasets import DictDataset\n",
    "from utils.general import set_seeds, ensure_tensor\n",
    "from utils.rf import calc_sta, plot_stas\n",
    "from utils.spikes import KilosortResults\n",
    "from utils.datasets import CombinedEmbeddedDataset\n",
    "from utils.modules import WindowedConv2d, SplitRelu\n",
    "from utils.reg import laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa4313-40e9-42e5-bf4f-3163fee56f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Set random seeds for reproducibility across runs\n",
    "RANDOM_SEED = 1002\n",
    "set_seeds(RANDOM_SEED)\n",
    "\n",
    "# Configure PyTorch for optimal performance\n",
    "torch.set_float32_matmul_precision('medium')  # Trade precision for speed\n",
    "\n",
    "# Set device for computation (GPU if available, otherwise CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define data directory path\n",
    "data_dir = Path('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a0da4e-4dd5-4141-ab97-70afd3bef0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 2. LOAD SHIFTED DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "# Load experimental metadata and stimulus information\n",
    "f_dset = data_dir / 'gaborium_corrected.dset'\n",
    "\n",
    "gabor_dataset = DictDataset.load(f_dset)\n",
    "gabor_dataset['stim'] = gabor_dataset['stim'].float()\n",
    "gabor_dataset['stim'] = (gabor_dataset['stim'] - 127) / 255\n",
    "print(gabor_dataset)\n",
    "\n",
    "f_natural_images = data_dir / 'natural_images.dset'\n",
    "ni_dataset = DictDataset.load(f_natural_images)\n",
    "ni_dataset['stim'] = ni_dataset['stim'].float()\n",
    "ni_dataset['stim'] = (ni_dataset['stim'] - 127) / 255\n",
    "print(ni_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150bdac-02e7-4f48-bda7-221a4a63c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# plot a gif of 240 frames of stim from each dataset side by side\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set up the figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.set_title('Gabor Dataset')\n",
    "ax2.set_title('Natural Images Dataset')\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Number of frames to animate\n",
    "n_frames = min(240, gabor_dataset['stim'].shape[0], ni_dataset['stim'].shape[0])\n",
    "\n",
    "# Initialize images\n",
    "im1 = ax1.imshow(gabor_dataset['stim'][0], cmap='gray', animated=True)\n",
    "im2 = ax2.imshow(ni_dataset['stim'][0], cmap='gray', animated=True)\n",
    "\n",
    "def animate(frame):\n",
    "    \"\"\"Update function for animation\"\"\"\n",
    "    im1.set_array(gabor_dataset['stim'][frame])\n",
    "    ax1.set_title(f'Gabor Dataset \\n Eye Position: {gabor_dataset['eyepos'][frame,0]:.3f}, {gabor_dataset['eyepos'][frame,1]:.3f}')\n",
    "    im2.set_array(ni_dataset['stim'][frame])\n",
    "    ax2.set_title(f'Natural Images Dataset \\n Eye Position: {ni_dataset['eyepos'][frame,0]:.3f}, {ni_dataset['eyepos'][frame,1]:.3f}')\n",
    "    fig.suptitle(f'Time: {frame/240*1000:.1f} ms')\n",
    "    return [im1, im2]\n",
    "\n",
    "# Create animation\n",
    "anim = animation.FuncAnimation(fig, animate, frames=n_frames, \n",
    "                              interval=50, blit=True, repeat=True)\n",
    "\n",
    "plt.close(fig)\n",
    "# Display in notebook\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a9272-fae5-4bf9-b4f9-522abd7fd47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3. DATA PREPROCESSING AND QUALITY CONTROL\n",
    "# ============================================================================\n",
    "# Before training neural network models, we need to:\n",
    "# 1. Identify valid time points for analysis (avoiding trial boundaries)\n",
    "# 2. Perform quality control to select high-quality neural units\n",
    "# 3. Split data into training, validation, and test sets\n",
    "\n",
    "def get_valid_inds(dset, n_lags):\n",
    "    \"\"\"\n",
    "    Find valid time indices for analysis, excluding trial boundaries and invalid periods.\n",
    "\n",
    "    When analyzing neural responses to visual stimuli, we need to exclude:\n",
    "    - Trial boundaries (where stimulus context changes abruptly)\n",
    "    - Periods marked as invalid in the dataset\n",
    "    - Time points too close to trial starts (within n_lags frames)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dset : DictDataset\n",
    "        Dataset containing trial indices and validity markers\n",
    "    n_lags : int\n",
    "        Number of stimulus history frames needed for each prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Indices of valid time points for analysis\n",
    "    \"\"\"\n",
    "    # Get validity markers from dataset (e.g., eye tracking quality)\n",
    "    dpi_valid = dset['dpi_valid']\n",
    "\n",
    "    # Detect trial boundaries (where trial index changes)\n",
    "    new_trials = torch.diff(dset['trial_inds'], prepend=torch.tensor([-1])) != 0\n",
    "\n",
    "    # Start with points that are not at trial boundaries and are marked valid\n",
    "    valid = ~new_trials\n",
    "    valid &= (dpi_valid > 0)\n",
    "\n",
    "    # Exclude points too close to trial boundaries (need n_lags history)\n",
    "    for iL in range(n_lags):\n",
    "        valid &= torch.roll(valid, iL)\n",
    "\n",
    "    # Return indices of valid time points\n",
    "    inds = torch.where(valid)[0]\n",
    "    return inds\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYSIS PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Number of stimulus history frames to include in model\n",
    "n_lags = 25  # 25 frames = ~100ms at 240Hz (typical retinal response latency)\n",
    "\n",
    "# Get dataset dimensions\n",
    "n_units = gabor_dataset['robs'].shape[1]  # Number of recorded neurons\n",
    "n_y, n_x = gabor_dataset['stim'].shape[1:3]  # Stimulus spatial dimensions\n",
    "\n",
    "# Find valid time indices for both datasets\n",
    "gabor_inds = get_valid_inds(gabor_dataset, n_lags)\n",
    "ni_inds = get_valid_inds(ni_dataset, n_lags)\n",
    "\n",
    "print(f\"Dataset dimensions:\")\n",
    "print(f\"  Stimulus: {n_y} x {n_x} pixels\")\n",
    "print(f\"  Units: {n_units} kilosort clusters\")\n",
    "print(f\"  Valid timepoints - Gabor: {len(gabor_inds)}, Natural Images: {len(ni_inds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9c44d-3cd1-4255-a34f-279663f70c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1 NEURAL UNIT QUALITY CONTROL\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Just because Kilosort identifies a cluster of waveforms doesn't mean\n",
    "the cluster corresponds to a single neuron (Type 1 errors), or that \n",
    "the waveforms contain all the spikes the neuron fires (Type 2 errors).\n",
    "\n",
    "We apply several quality control checks to select the units we model.\n",
    "\n",
    "1. Visual responsiveness:\n",
    "   - Measured using spike-triggered stimulus energy (STE)\n",
    "   - Finds clusters that respond to stimulus area in localized area of the visual field\n",
    "\n",
    "2. Refractory period violations:\n",
    "   - Real neurons have ~1-2ms refractory periods where they cannot spike\n",
    "   - Violations suggest contamination from nearby neurons\n",
    "\n",
    "3. Amplitude distribution:\n",
    "   - Kilosort sets a hard amplitude threshold on spike detection\n",
    "   - Many spikes from a given neuron may fall below this threshold and not be detected\n",
    "   - The amplitude distribution of detected spikes can reveal this by \n",
    "     the presence of a truncation in the amplitude distribution\n",
    "   - The distribution of missing spikes can change over time, so must be tracked\n",
    "\"\"\"\n",
    "\n",
    "# Quality thresholds for unit selection\n",
    "SNR_THRESHOLD = 6  # Signal-to-noise ratio threshold for visual responsiveness\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1.1 VISUAL RESPONSIVENESS ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Analyzing neural response timing and visual responsiveness...\")\n",
    "print(\"Computing spike-triggered stimulus energies...\")\n",
    "\n",
    "# Calculate spike-triggered stimulus energy (STE)\n",
    "# STE measures how much stimulus energy drives each neuron at different time lags\n",
    "# This is like a \"reverse correlation\" - what stimulus patterns preceded each spike?\n",
    "spike_triggered_energies = calc_sta(\n",
    "    gabor_dataset['stim'], gabor_dataset['robs'],\n",
    "    n_lags, inds=gabor_inds, device=device, batch_size=10000,\n",
    "    stim_modifier=lambda x: x**2,  # Square stimulus to get energy (not contrast)\n",
    "    progress=True\n",
    ").cpu().numpy()\n",
    "\n",
    "print(f\"Computed STEs for {spike_triggered_energies.shape[0]} units, \"\n",
    "      f\"{spike_triggered_energies.shape[1]} time lags\")\n",
    "\n",
    "# Find the optimal response lag for each neuron\n",
    "# We look for the lag that gives the strongest, most reliable response\n",
    "# Subtract median to remove baseline and focus on stimulus-driven modulation\n",
    "signal_strength = np.abs(spike_triggered_energies -\n",
    "                        np.median(spike_triggered_energies, axis=(2,3), keepdims=True))\n",
    "\n",
    "# Apply spatial smoothing to reduce noise while preserving signal structure\n",
    "smoothing_kernel = [0, 2, 2, 2]  # [time, y, x] - no temporal, 2-pixel spatial smoothing\n",
    "signal_strength = gaussian_filter(signal_strength, smoothing_kernel)\n",
    "\n",
    "# Calculate signal-to-noise ratio for each unit\n",
    "# Use first lag (earliest time) as noise estimate since visual responses are delayed\n",
    "noise_level = np.median(signal_strength[:, 0], axis=(1,2))\n",
    "signal_to_noise = np.max(signal_strength, axis=(1,2,3)) / noise_level\n",
    "\n",
    "# Visualize the distribution of signal-to-noise ratios\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(signal_to_noise, bins=100, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(SNR_THRESHOLD, color='red', linestyle='--', linewidth=2,\n",
    "           label=f'Threshold = {SNR_THRESHOLD}')\n",
    "plt.xlabel('Signal-to-Noise Ratio')\n",
    "plt.ylabel('Number of Units')\n",
    "plt.title('Distribution of Visual Responsiveness (Signal-to-Noise Ratios)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Select visually responsive units\n",
    "visually_responsive_units = np.where(signal_to_noise > SNR_THRESHOLD)[0]\n",
    "print(f'✅ {len(visually_responsive_units)} / {n_units} units pass visual responsiveness criteria')\n",
    "print(f'   ({len(visually_responsive_units)/n_units*100:.1f}% of recorded units)')\n",
    "\n",
    "if len(visually_responsive_units) == 0:\n",
    "    print(\"⚠️  WARNING: No units pass visual responsiveness criteria!\")\n",
    "    print(\"   Consider lowering SNR_THRESHOLD or checking data quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42369b-f89e-4a42-813d-c3f5c1286b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1.2 REFRACTORY PERIOD ANALYSIS\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Real neurons have a refractory period (~1-2ms) after each spike during which\n",
    "they cannot fire again. Violations of this biological constraint indicate:\n",
    "- Contamination from nearby neurons (spike sorting errors)\n",
    "- Noise artifacts being classified as spikes\n",
    "\n",
    "We analyze inter-spike interval (ISI) distributions to estimate contamination.\n",
    "This analysis was originally developed by the Steinmetz Lab and adapted by Ryan Ressmeyer.\n",
    "For the original code see: \n",
    "    https://github.com/SteinmetzLab/slidingRefractory\n",
    "\"\"\"\n",
    "\n",
    "print(\"Loading spike sorting results and analyzing refractory periods...\")\n",
    "\n",
    "# Load spike sorting results from Kilosort4\n",
    "ks4_dir = data_dir / 'Allen_2022-04-13_ks4'\n",
    "ks_results = KilosortResults(ks4_dir)\n",
    "\n",
    "# Extract spike data\n",
    "spike_times = ks_results.spike_times  # When each spike occurred (in seconds)\n",
    "spike_amplitudes = ks_results.spike_amplitudes  # Amplitude of each spike\n",
    "spike_clusters = ks_results.spike_clusters  # Which neuron each spike came from\n",
    "cluster_ids = np.unique(spike_clusters)  # List of all neuron IDs\n",
    "\n",
    "print(f\"Loaded spike data:\")\n",
    "print(f\"  {len(cluster_ids)} units\")\n",
    "print(f\"  {len(spike_times)} total spikes\")\n",
    "print(f\"  Recording duration: {spike_times.max():.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd2a74-231b-4108-901f-9624c6fa4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Compute contamination estimates across different refractory period assumptions\n",
    "from utils.qc import compute_min_contam_props, plot_min_contam_prop\n",
    "\n",
    "print(\"Computing contamination estimates...\")\n",
    "\n",
    "# Test range of refractory periods (1-10ms)\n",
    "refractory_periods = np.exp(np.linspace(np.log(1e-3), np.log(10e-3), 100))\n",
    "\n",
    "# Compute minimum contamination proportion for each unit\n",
    "# This estimates what fraction of spikes are likely contamination\n",
    "min_contam_props, firing_rates = compute_min_contam_props(\n",
    "    spike_times, spike_clusters,\n",
    "    refractory_periods=refractory_periods,\n",
    "    ref_acg_t_start=.25e-3,  # Start analysis at 0.25ms (absolute refractory period)\n",
    "    progress=True\n",
    ")\n",
    "\n",
    "# Take the minimum contamination across all tested refractory periods\n",
    "contam_props = min_contam_props.min(axis=1)\n",
    "\n",
    "# Visualize contamination distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(contam_props, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Contamination Proportion')\n",
    "plt.ylabel('Number of Units')\n",
    "plt.title('Distribution of Estimated Contamination')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(firing_rates, contam_props, alpha=0.6)\n",
    "plt.xlabel('Firing Rate (Hz)')\n",
    "plt.ylabel('Contamination Proportion')\n",
    "plt.title('Contamination vs Firing Rate')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show examples of units with different contamination levels\n",
    "print(\"\\nExample units with different contamination levels:\")\n",
    "for prop in [0, 20, 50, 80, 100]:\n",
    "    closest_ind = np.argmin(np.abs(contam_props - prop/100))\n",
    "    unit_id = cluster_ids[closest_ind]\n",
    "\n",
    "    print(f'{prop}% contamination example: Unit {unit_id}')\n",
    "\n",
    "    # Plot detailed analysis for this unit\n",
    "    fig, axs = plot_min_contam_prop(\n",
    "        spike_times[spike_clusters == unit_id],\n",
    "        min_contam_props[closest_ind],\n",
    "        refractory_periods\n",
    "    )\n",
    "\n",
    "    # Add informative title\n",
    "    n_spikes = np.sum(spike_clusters == unit_id)\n",
    "    axs.set_title(f'Unit {unit_id} - {n_spikes} spikes '\n",
    "                 f'({firing_rates[closest_ind]:.2f} Hz) - '\n",
    "                 f'{contam_props[closest_ind]*100:.1f}% contamination')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b85542-e419-40df-b787-38bfdd081acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1.3 APPLY CONTAMINATION THRESHOLD\n",
    "# ============================================================================\n",
    "\n",
    "# Set contamination threshold\n",
    "CONTAMINATION_THRESHOLD = 0.75  # Allow up to 75% contamination\n",
    "\n",
    "print(f\"Applying contamination threshold of {CONTAMINATION_THRESHOLD*100}%...\")\n",
    "\n",
    "# Find units that pass both visual responsiveness AND contamination criteria\n",
    "contamination_pass = np.where(contam_props <= CONTAMINATION_THRESHOLD)[0]\n",
    "included_units = np.intersect1d(contamination_pass, visually_responsive_units)\n",
    "\n",
    "print(f\"Quality control summary:\")\n",
    "print(f\"  Visual responsiveness: {len(visually_responsive_units)}/{len(cluster_ids)} units\")\n",
    "print(f\"  Contamination < {CONTAMINATION_THRESHOLD*100}%: {len(contamination_pass)}/{len(cluster_ids)} units\")\n",
    "print(f\"  ✅ Both criteria: {len(included_units)}/{len(cluster_ids)} units\")\n",
    "print(f\"  Final inclusion rate: {len(included_units)/len(cluster_ids)*100:.1f}%\")\n",
    "\n",
    "# Update datasets to include only high-quality units\n",
    "gabor_dataset['robs'] = gabor_dataset['robs'][:, included_units]\n",
    "ni_dataset['robs'] = ni_dataset['robs'][:, included_units]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e006ca-db48-4c90-8894-4f0c88e31cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1.4 VISUALIZE SPIKE CHARACTERISTICS\n",
    "# ============================================================================\n",
    "\n",
    "# Show example spike characteristics for a representative unit\n",
    "if len(included_units) > 5:\n",
    "    example_unit_idx = 5\n",
    "    example_unit = cluster_ids[included_units[example_unit_idx]]\n",
    "else:\n",
    "    example_unit_idx = 0\n",
    "    example_unit = cluster_ids[included_units[example_unit_idx]]\n",
    "\n",
    "print(f\"Examining spike characteristics for Unit {example_unit}...\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5), width_ratios=[2, 1])\n",
    "\n",
    "# Plot 1: Spike amplitudes over time\n",
    "plt.subplot(121)\n",
    "unit_mask = spike_clusters == example_unit\n",
    "unit_times = spike_times[unit_mask]\n",
    "unit_amps = spike_amplitudes[unit_mask]\n",
    "\n",
    "plt.hist2d(unit_times, unit_amps, bins=(200, 50), cmap='Purples')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Spike Amplitude (a.u.)')\n",
    "plt.title(f'Unit {example_unit}: Spike Amplitudes Over Time')\n",
    "plt.colorbar(label='Spike Count')\n",
    "\n",
    "# Plot 2: Inter-spike interval distribution\n",
    "plt.subplot(122)\n",
    "isis = np.diff(unit_times) * 1000  # Convert to milliseconds\n",
    "plt.hist(isis, bins=np.linspace(0, 10, 50), alpha=0.7, edgecolor='black')\n",
    "plt.axvline(2, color='red', linestyle='--', label='2ms refractory period')\n",
    "plt.xlabel('Inter-Spike Interval (ms)')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'ISI Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Unit {example_unit} statistics:\")\n",
    "print(f\"  Total spikes: {len(unit_times)}\")\n",
    "print(f\"  Firing rate: {len(unit_times)/(unit_times.max()-unit_times.min()):.2f} Hz\")\n",
    "print(f\"  Refractory violations (<2ms): {np.sum(isis < 2)} ({np.sum(isis < 2)/len(isis)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d409f-4deb-4bb2-8733-008a3c91a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1.5 AMPLITUDE STABILITY ANALYSIS\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Kilosort uses a hard amplitude threshold to detect spikes.\n",
    "This can lead to missing spikes from weak neural responses.\n",
    "\n",
    "We track the \"missing percentage\" (MPCT) over time to identify periods\n",
    "of poor recording quality that should be excluded from analysis.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Analyzing spike amplitude stability over time...\")\n",
    "\n",
    "from utils.qc import analyze_amplitude_truncation, plot_amplitude_truncation\n",
    "\n",
    "# Analyze amplitude stability for all units\n",
    "amplitude_results = []\n",
    "\n",
    "print(\"Computing amplitude truncation analysis for all units...\")\n",
    "for iU in tqdm(cluster_ids, desc=\"Analyzing units\"):\n",
    "    # Get spikes for this unit\n",
    "    st_clu = spike_times[spike_clusters == iU]\n",
    "    amp_clu = spike_amplitudes[spike_clusters == iU]\n",
    "\n",
    "    # Analyze amplitude changes over time\n",
    "    window_blocks, valid_blocks, popts, mpcts = analyze_amplitude_truncation(\n",
    "        st_clu, amp_clu, max_isi=np.inf\n",
    "    )\n",
    "\n",
    "    amplitude_results.append({\n",
    "        'cid': iU,\n",
    "        'window_blocks': window_blocks,\n",
    "        'valid_blocks': valid_blocks,\n",
    "        'popts': popts,\n",
    "        'mpcts': mpcts,  # Missing percentage over time\n",
    "    })\n",
    "\n",
    "print(f\"Completed amplitude analysis for {len(amplitude_results)} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c91c1-1ac6-4008-a546-098a46fdf2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1.6 VISUALIZE AMPLITUDE STABILITY EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "# Show detailed amplitude analysis for the same example unit\n",
    "example_unit_global_idx = np.where(cluster_ids == example_unit)[0][0]\n",
    "\n",
    "print(f\"Detailed amplitude analysis for Unit {example_unit}:\")\n",
    "\n",
    "fig, axs = plot_amplitude_truncation(\n",
    "    spike_times[spike_clusters == example_unit],\n",
    "    spike_amplitudes[spike_clusters == example_unit],\n",
    "    amplitude_results[example_unit_global_idx]['window_blocks'],\n",
    "    amplitude_results[example_unit_global_idx]['valid_blocks'],\n",
    "    amplitude_results[example_unit_global_idx]['mpcts'],\n",
    ")\n",
    "\n",
    "axs.set_title(f'Unit {example_unit}: Amplitude Stability Analysis\\n'\n",
    "             f'Red line shows estimated \"missing percentage\" over time')\n",
    "plt.show()\n",
    "\n",
    "# Explain what we're seeing\n",
    "mpcts = amplitude_results[example_unit_global_idx]['mpcts']\n",
    "if len(mpcts) > 0:\n",
    "    print(f\"Missing percentage range: {np.min(mpcts):.1f}% - {np.max(mpcts):.1f}%\")\n",
    "    print(f\"Average missing percentage: {np.mean(mpcts):.1f}%\")\n",
    "else:\n",
    "    print(\"No amplitude windows detected for this unit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3431dfa-0fbd-425b-b9f0-7cca70e472d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1.7 APPLY AMPLITUDE-BASED QUALITY CONTROL\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Here we use the amplitude analysis to create a time-varying quality mask\n",
    "for each unit. We refer to this mask as the \"data filters\" (dfs) for each unit.\n",
    "This allows us to exclude periods of poor recording quality from the loss\n",
    "calculation when training the model. \n",
    "\"\"\"\n",
    "\n",
    "# Set threshold for missing percentage\n",
    "MPCT_THRESHOLD = 30  # Exclude periods with >30% estimated missing spikes\n",
    "\n",
    "print(f\"Creating time-varying quality masks (MPCT threshold: {MPCT_THRESHOLD}%)...\")\n",
    "\n",
    "# Initialize quality masks (degrees of freedom) for both datasets\n",
    "gabor_dfs = torch.zeros_like(gabor_dataset['robs'])\n",
    "ni_dfs = torch.zeros_like(ni_dataset['robs'])\n",
    "\n",
    "# Process each included unit\n",
    "for iU, uid in enumerate(included_units):\n",
    "    # Get spike times for this unit\n",
    "    st_clu = spike_times[spike_clusters == uid]\n",
    "\n",
    "    # Get amplitude analysis results\n",
    "    uid_idx = np.where(cluster_ids == uid)[0][0]  # Find index in amplitude_results\n",
    "    window_blocks = np.array(amplitude_results[uid_idx]['window_blocks']).flatten()\n",
    "\n",
    "    if len(window_blocks) == 0:\n",
    "        # No amplitude windows detected - include all timepoints\n",
    "        gabor_dfs[:, iU] = 1\n",
    "        ni_dfs[:, iU] = 1\n",
    "        continue\n",
    "\n",
    "    # Get times corresponding to amplitude windows\n",
    "    window_times = st_clu[window_blocks]\n",
    "    mpcts = amplitude_results[uid_idx]['mpcts']\n",
    "\n",
    "    # Interpolate missing percentages to dataset time bins\n",
    "    # Use linear interpolation with constant extrapolation\n",
    "    mpct_interpolant = interp1d(\n",
    "        window_times, np.repeat(mpcts, 2),\n",
    "        kind='linear', fill_value=50, bounds_error=False\n",
    "    )\n",
    "\n",
    "    # Apply to both datasets\n",
    "    mpct_bins_gabor = mpct_interpolant(gabor_dataset['t_bins'])\n",
    "    gabor_dfs[:, iU] = torch.from_numpy(mpct_bins_gabor < MPCT_THRESHOLD).float()\n",
    "\n",
    "    mpct_bins_ni = mpct_interpolant(ni_dataset['t_bins'])\n",
    "    ni_dfs[:, iU] = torch.from_numpy(mpct_bins_ni < MPCT_THRESHOLD).float()\n",
    "\n",
    "# Add quality masks to datasets\n",
    "gabor_dataset['dfs'] = gabor_dfs\n",
    "ni_dataset['dfs'] = ni_dfs\n",
    "\n",
    "print(f'Time bins passing MPCT threshold:')\n",
    "print(f'  Gabor dataset: {gabor_dfs.mean().item():.1%}')\n",
    "print(f'  Natural images dataset: {ni_dfs.mean().item():.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e1df3-5cd5-4be6-ba4d-e1fdf21bd5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1.8 FINAL UNIT SELECTION\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Apply final criterion: units must have sufficient spikes in both datasets\n",
    "after all quality control measures.\n",
    "\"\"\"\n",
    "\n",
    "MIN_SPIKE_COUNT = 500  # Minimum number of high-quality spikes required per unit\n",
    "\n",
    "print(f\"Applying final spike count criterion (minimum {MIN_SPIKE_COUNT} spikes)...\")\n",
    "\n",
    "# Count high-quality spikes for each unit in each dataset\n",
    "spikes_after_qc_gabor = (gabor_dataset['robs'] * gabor_dataset['dfs']).sum(0)\n",
    "spikes_after_qc_ni = (ni_dataset['robs'] * ni_dataset['dfs']).sum(0)\n",
    "\n",
    "# Find units with sufficient spikes in BOTH datasets\n",
    "sufficient_spikes = (spikes_after_qc_gabor > MIN_SPIKE_COUNT) & (spikes_after_qc_ni > MIN_SPIKE_COUNT)\n",
    "final_units = np.where(sufficient_spikes)[0]\n",
    "\n",
    "print(f\"Final unit selection:\")\n",
    "print(f\"  Units after initial QC: {len(included_units)}\")\n",
    "print(f\"  Units with >{MIN_SPIKE_COUNT} spikes in Gabor: {(spikes_after_qc_gabor > MIN_SPIKE_COUNT).sum()}\")\n",
    "print(f\"  Units with >{MIN_SPIKE_COUNT} spikes in NI: {(spikes_after_qc_ni > MIN_SPIKE_COUNT).sum()}\")\n",
    "print(f\"  ✅ Final units for modeling: {len(final_units)}\")\n",
    "\n",
    "# Update datasets to include only final units\n",
    "gabor_dataset['robs'] = gabor_dataset['robs'][:, final_units]\n",
    "gabor_dataset['dfs'] = gabor_dataset['dfs'][:, final_units]\n",
    "ni_dataset['robs'] = ni_dataset['robs'][:, final_units]\n",
    "ni_dataset['dfs'] = ni_dataset['dfs'][:, final_units]\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\nFinal dataset summary:\")\n",
    "print(f\"  Total high-quality spikes in Gabor: {(gabor_dataset['robs'] * gabor_dataset['dfs']).sum().item():.0f}\")\n",
    "print(f\"  Total high-quality spikes in NI: {(ni_dataset['robs'] * ni_dataset['dfs']).sum().item():.0f}\")\n",
    "print(f\"  Average firing rate per unit: {(gabor_dataset['robs'] * gabor_dataset['dfs']).sum(0).mean().item():.1f} spikes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080a38f-4d45-43ab-b75d-632c4db4bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 3.2 VISUALIZE RECEPTIVE FIELDS\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Now that we have high-quality units, let's visualize their receptive fields\n",
    "using spike-triggered averages (STAs). This helps us understand what visual\n",
    "features each neuron responds to.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Computing spike-triggered averages (STAs) for final units...\")\n",
    "\n",
    "# Compute STAs using contrast (mean-subtracted stimulus)\n",
    "stas = calc_sta(\n",
    "    gabor_dataset['stim'] - gabor_dataset['stim'].mean(),\n",
    "    gabor_dataset['robs'],\n",
    "    n_lags, inds=gabor_inds, device=device, batch_size=10000,\n",
    "    progress=True\n",
    ").cpu().numpy()\n",
    "\n",
    "print(f\"Computed STAs for {stas.shape[0]} units\")\n",
    "\n",
    "# Visualize receptive fields\n",
    "print(\"Displaying receptive field maps...\")\n",
    "fig, axs = plot_stas(stas[:, :, None, :, :])\n",
    "axs.set_title('Spike-Triggered Average (STA)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515dc8f-ebbc-423c-819b-3c692775f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Also compute spike-triggered energies for comparison\n",
    "print(\"Computing spike-triggered energies (STEs)...\")\n",
    "\n",
    "stes = calc_sta(\n",
    "    gabor_dataset['stim'], gabor_dataset['robs'],\n",
    "    n_lags, device=device, batch_size=10000,\n",
    "    stim_modifier=lambda x: x**2,  # Square for energy\n",
    "    progress=True\n",
    ").cpu().numpy()\n",
    "\n",
    "# Remove mean to highlight stimulus-driven modulation\n",
    "stes -= stes.mean(axis=(1, 2, 3), keepdims=True)\n",
    "\n",
    "print(\"Displaying energy-based receptive field maps...\")\n",
    "fig, axs = plot_stas(stes[:, :, None, :, :])\n",
    "axs.set_title('Spike-Triggered Energy (STE)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb5f18-0e9f-453d-a476-ba1e18e41509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 4. DATA SPLITTING AND DATASET PREPARATION\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "For robust model evaluation, we need to split our data into:\n",
    "- Training set: Used to optimize model parameters\n",
    "- Validation set: Used for hyperparameter tuning and early stopping\n",
    "- Test set: Used for final, unbiased performance evaluation\n",
    "\n",
    "Important: We split by TRIALS, not individual timepoints, to avoid\n",
    "data leakage between sets.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define which data keys need which temporal lags\n",
    "keys_lags = {\n",
    "    'robs': 0,        # Neural responses (current timepoint)\n",
    "    'dfs': 0,         # Quality flags (current timepoint)\n",
    "    'stim': np.arange(n_lags),  # Stimulus history (past n_lags timepoints)\n",
    "}\n",
    "\n",
    "print(\"Setting up data splitting strategy...\")\n",
    "print(f\"Using {n_lags} stimulus history frames for each prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2576a16-7397-4562-bb43-cc23cf26911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 4.1 TRIAL-BASED DATA SPLITTING FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def split_inds_by_trial(dset, inds, splits, seed=1002):\n",
    "    \"\"\"\n",
    "    Split data indices by trial to avoid data leakage between train/val/test sets.\n",
    "\n",
    "    This is crucial for neural data analysis because consecutive timepoints\n",
    "    within a trial are highly correlated. Random splitting would allow the\n",
    "    model to \"cheat\" by learning from nearby timepoints.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dset : DictDataset\n",
    "        Dataset containing trial indices\n",
    "    inds : torch.Tensor\n",
    "        Valid time indices to split\n",
    "    splits : list of float\n",
    "        Fraction of trials for each split (must sum to ≤1)\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of torch.Tensor\n",
    "        Time indices for each split\n",
    "    \"\"\"\n",
    "    assert np.sum(splits) <= 1, 'Split fractions must sum to 1 or less'\n",
    "\n",
    "    # Set random seed for reproducible splits\n",
    "    set_seeds(seed)\n",
    "\n",
    "    # Get unique trial IDs and randomize their order\n",
    "    trials = dset['trial_inds'].unique()\n",
    "    rand_trials = torch.randperm(len(trials))\n",
    "\n",
    "    # Calculate number of trials for each split\n",
    "    split_sizes = [int(len(trials) * split) for split in splits]\n",
    "\n",
    "    # Assign trials to each split\n",
    "    split_trials = []\n",
    "    start_idx = 0\n",
    "    for size in split_sizes:\n",
    "        end_idx = start_idx + size\n",
    "        split_trials.append(trials[rand_trials[start_idx:end_idx]])\n",
    "        start_idx = end_idx\n",
    "\n",
    "    # Convert trial assignments to time index assignments\n",
    "    split_inds = []\n",
    "    for trial_subset in split_trials:\n",
    "        # Find time indices belonging to trials in this split\n",
    "        mask = torch.isin(dset['trial_inds'][inds], trial_subset)\n",
    "        split_inds.append(inds[mask])\n",
    "\n",
    "    return split_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302088a1-3bf2-44d2-8a6c-1d19a400b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 4.2 CREATE TRAIN/VALIDATION/TEST SPLITS\n",
    "# ============================================================================\n",
    "\n",
    "# Define split proportions\n",
    "train_val_test_split = [0.6, 0.2, 0.2]  # 60% train, 20% val, 20% test\n",
    "\n",
    "print(\"Creating trial-based data splits...\")\n",
    "\n",
    "# Split Gabor dataset\n",
    "gabor_train_inds, gabor_val_inds, gabor_test_inds = split_inds_by_trial(\n",
    "    gabor_dataset, gabor_inds, train_val_test_split\n",
    ")\n",
    "\n",
    "print(f'Gabor dataset splits:')\n",
    "print(f'  Train: {len(gabor_train_inds):,} samples ({len(gabor_train_inds)/len(gabor_inds):.1%})')\n",
    "print(f'  Val:   {len(gabor_val_inds):,} samples ({len(gabor_val_inds)/len(gabor_inds):.1%})')\n",
    "print(f'  Test:  {len(gabor_test_inds):,} samples ({len(gabor_test_inds)/len(gabor_inds):.1%})')\n",
    "\n",
    "# Split Natural Images dataset\n",
    "ni_train_inds, ni_val_inds, ni_test_inds = split_inds_by_trial(\n",
    "    ni_dataset, ni_inds, train_val_test_split\n",
    ")\n",
    "\n",
    "print(f'\\nNatural Images dataset splits:')\n",
    "print(f'  Train: {len(ni_train_inds):,} samples ({len(ni_train_inds)/len(ni_inds):.1%})')\n",
    "print(f'  Val:   {len(ni_val_inds):,} samples ({len(ni_val_inds)/len(ni_inds):.1%})')\n",
    "print(f'  Test:  {len(ni_test_inds):,} samples ({len(ni_test_inds)/len(ni_inds):.1%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0cb9fd-9003-45a9-a562-c170779b4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 4.3 CREATE PYTORCH DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nCreating PyTorch datasets with temporal embedding...\")\n",
    "\n",
    "# Individual dataset splits\n",
    "gabor_train_dataset = CombinedEmbeddedDataset(gabor_dataset, gabor_train_inds, keys_lags, 'cpu')\n",
    "gabor_val_dataset = CombinedEmbeddedDataset(gabor_dataset, gabor_val_inds, keys_lags, 'cpu')\n",
    "gabor_test_dataset = CombinedEmbeddedDataset(gabor_dataset, gabor_test_inds, keys_lags, 'cpu')\n",
    "\n",
    "ni_train_dataset = CombinedEmbeddedDataset(ni_dataset, ni_train_inds, keys_lags, 'cpu')\n",
    "ni_val_dataset = CombinedEmbeddedDataset(ni_dataset, ni_val_inds, keys_lags, 'cpu')\n",
    "ni_test_dataset = CombinedEmbeddedDataset(ni_dataset, ni_test_inds, keys_lags, 'cpu')\n",
    "\n",
    "# Combined datasets (for training on both stimulus types)\n",
    "both_train_dataset = CombinedEmbeddedDataset(\n",
    "    [gabor_dataset, ni_dataset], [gabor_train_inds, ni_train_inds], keys_lags, 'cpu'\n",
    ")\n",
    "both_val_dataset = CombinedEmbeddedDataset(\n",
    "    [gabor_dataset, ni_dataset], [gabor_val_inds, ni_val_inds], keys_lags, 'cpu'\n",
    ")\n",
    "both_test_dataset = CombinedEmbeddedDataset(\n",
    "    [gabor_dataset, ni_dataset], [gabor_test_inds, ni_test_inds], keys_lags, 'cpu'\n",
    ")\n",
    "\n",
    "print(\"Dataset creation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7338b0-712f-4aba-bbe0-c2c577c2da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 4.4 TEST DATASET STRUCTURE\n",
    "# ============================================================================\n",
    "\n",
    "# Examine the structure of our processed datasets\n",
    "print(\"Examining dataset structure...\")\n",
    "test_batch = both_train_dataset[:64]\n",
    "\n",
    "print(\"Batch contents:\")\n",
    "for k, v in test_batch.items():\n",
    "    print(f\"  {k}: {v.shape} ({v.dtype})\")\n",
    "\n",
    "print(f\"\\nStimulus tensor interpretation:\")\n",
    "print(f\"  Shape: [batch_size, n_lags, height, width]\")\n",
    "print(f\"  Contains {test_batch['stim'].shape[1]} frames of stimulus history\")\n",
    "print(f\"  Spatial resolution: {test_batch['stim'].shape[2]} x {test_batch['stim'].shape[3]} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7675542-5da6-4e11-80f9-58395e0adb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# ============================================================================\n",
    "# 5. NEURAL NETWORK ARCHITECTURE\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "This section defines the neural network architecture for modeling neural responses.\n",
    "We use a lightweight spatiotemporal CNN with residual connections to capture both spatial\n",
    "and temporal dependencies in the stimulus-response relationship.\n",
    "\"\"\"\n",
    "\n",
    "class SpatioTemporalResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatiotemporal CNN with residual connections for modeling neural responses.\n",
    "\n",
    "    Architecture:\n",
    "    1. Temporal layer: Processes stimulus history with 1x1 convolutions\n",
    "    2. Spatial layers: Process spatial features with residual connections\n",
    "    3. Readout layer: Maps features to individual neuron predictions\n",
    "\n",
    "    The residual connections help with gradient flow during training and\n",
    "    allow the model to learn both simple and complex feature combinations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_lags, n_y, n_x, n_units, temporal_channels, res_channels,\n",
    "                 kernel_size, n_layers, baseline_rates=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_lags : int\n",
    "            Number of stimulus history frames\n",
    "        n_y, n_x : int\n",
    "            Spatial dimensions of stimulus\n",
    "        n_units : int\n",
    "            Number of neurons to model\n",
    "        temporal_channels : int\n",
    "            Number of channels after temporal processing\n",
    "        res_channels : int\n",
    "            Number of channels in residual layers\n",
    "        kernel_size : int\n",
    "            Spatial kernel size for convolutional layers\n",
    "        n_layers : int\n",
    "            Number of spatial processing layers\n",
    "        baseline_rates : array-like, optional\n",
    "            Baseline firing rates for initializing readout bias\n",
    "        \"\"\"\n",
    "        super(SpatioTemporalResNet, self).__init__()\n",
    "\n",
    "        # Temporal processing: combine stimulus history\n",
    "        self.temporal_layer = nn.Conv2d(n_lags, temporal_channels, kernel_size=1, bias=False)\n",
    "        self.temporal_activation = SplitRelu()  # Separate positive/negative channels\n",
    "\n",
    "        # Spatial processing layers with residual connections\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        for iC in range(n_layers):\n",
    "            in_channels = temporal_channels*2 if iC == 0 else res_channels\n",
    "            self.layers.append(WindowedConv2d(in_channels, res_channels,\n",
    "                                            kernel_size=kernel_size, bias=True))\n",
    "\n",
    "        # Channel projection for residual connections (if needed)\n",
    "        if temporal_channels*2 != res_channels:\n",
    "            self.channel_projection = nn.Conv2d(temporal_channels*2, res_channels,\n",
    "                                              kernel_size=1, bias=False)\n",
    "        else:\n",
    "            self.channel_projection = None\n",
    "\n",
    "        # Calculate output spatial dimensions after convolutions\n",
    "        contraction = (kernel_size - 1) * n_layers\n",
    "        output_dims = [res_channels, n_y - contraction, n_x - contraction]\n",
    "\n",
    "        # Readout layer: map spatial features to neuron responses\n",
    "        self.readout = NonparametricReadout(output_dims, n_units, bias=True)\n",
    "\n",
    "        # Initialize readout bias with baseline firing rates\n",
    "        if baseline_rates is not None:\n",
    "            assert len(baseline_rates) == n_units, 'baseline_rates must match n_units'\n",
    "            # Convert rates to log-space for softplus activation\n",
    "            inv_softplus = lambda x: torch.log(torch.exp(x) - 1)\n",
    "            self.readout.bias.data = inv_softplus(\n",
    "                ensure_tensor(baseline_rates, device=self.readout.bias.device)\n",
    "            )\n",
    "\n",
    "    def forward(self, batch, debug=False):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : dict\n",
    "            Batch containing 'stim' key with stimulus tensor\n",
    "        debug : bool, optional\n",
    "            If True, print intermediate tensor shapes\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Input batch with added 'rhat' key containing predictions\n",
    "        \"\"\"\n",
    "        x = batch['stim']  # Shape: [batch, n_lags, height, width]\n",
    "        if debug:\n",
    "            print(f'Input stimulus: {x.shape}')\n",
    "\n",
    "        # Temporal processing: combine stimulus history\n",
    "        x = self.temporal_layer(x)  # Shape: [batch, temporal_channels, height, width]\n",
    "        x = self.temporal_activation(x)  # Shape: [batch, temporal_channels*2, height, width]\n",
    "        if debug:\n",
    "            print(f'After temporal processing: {x.shape}')\n",
    "\n",
    "        # Store input for residual connections\n",
    "        residual = x\n",
    "        if self.channel_projection is not None:\n",
    "            residual = self.channel_projection(residual)\n",
    "\n",
    "        # Spatial processing with residual connections\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)  # Spatial convolution\n",
    "            x = F.relu(x)  # Nonlinearity\n",
    "\n",
    "            # Add residual connection (crop residual to match current x size)\n",
    "            if residual.shape[-2:] != x.shape[-2:]:\n",
    "                # Calculate spatial cropping needed due to convolution\n",
    "                h_diff = residual.shape[-2] - x.shape[-2]\n",
    "                w_diff = residual.shape[-1] - x.shape[-1]\n",
    "                h_crop = h_diff // 2\n",
    "                w_crop = w_diff // 2\n",
    "                residual = residual[..., h_crop:h_crop+x.shape[-2], w_crop:w_crop+x.shape[-1]]\n",
    "\n",
    "            x = x + residual  # Residual connection\n",
    "            residual = x  # Update residual for next layer\n",
    "\n",
    "            if debug:\n",
    "                print(f'After spatial layer {i+1}: {x.shape}')\n",
    "\n",
    "        # Readout: map spatial features to neuron predictions\n",
    "        x = self.readout(x)  # Shape: [batch, n_units]\n",
    "        if debug:\n",
    "            print(f'After readout: {x.shape}')\n",
    "\n",
    "        # Apply softplus to ensure positive firing rates\n",
    "        batch['rhat'] = F.softplus(x)\n",
    "        return batch\n",
    "\n",
    "    def temporal_smoothness_regularization(self):\n",
    "        \"\"\"\n",
    "        Compute temporal smoothness regularization term.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Regularization loss term\n",
    "        \"\"\"\n",
    "        return laplacian(self.temporal_layer.weight, dims=1)\n",
    "\n",
    "    def plot_weights(self, name=None):\n",
    "        \"\"\"Visualize learned model weights.\"\"\"\n",
    "        prepend = (name + ' - ') if name is not None else ''\n",
    "        # Plot temporal filters\n",
    "        temporal_weights = self.temporal_layer.weight.detach().cpu().numpy()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(temporal_weights.squeeze().T)\n",
    "        plt.xlabel('Time Lag')\n",
    "        plt.ylabel('Weight')\n",
    "        plt.title(prepend + 'Learned Temporal Filters')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "        # Plot spatial filters for each layer\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if hasattr(layer, 'plot_weights'):\n",
    "                fig, _ = layer.plot_weights()\n",
    "                fig.suptitle(prepend + f'Spatial Layer {i+1} Filters')\n",
    "                plt.show()\n",
    "\n",
    "        # Plot readout weights\n",
    "        fig, _ = self.readout.plot_weights()\n",
    "        fig.suptitle(prepend + 'Readout Weights (Spatial to Neural Mapping)')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f58e1-42dd-4405-94a0-4ef8c90be16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 5.1 MODEL INSTANTIATION AND TESTING\n",
    "# ============================================================================\n",
    "\n",
    "# Get dataset dimensions for model architecture\n",
    "_, n_y, n_x = gabor_dataset['stim'].shape\n",
    "n_units = gabor_dataset['robs'].shape[1]\n",
    "\n",
    "# Model hyperparameters\n",
    "temporal_channels = 4   # Number of temporal feature channels\n",
    "res_channels = 8       # Number of channels in residual layers\n",
    "kernel_size = 13       # Spatial kernel size (13x13 pixels)\n",
    "n_layers = 4          # Number of spatial processing layers\n",
    "\n",
    "print(f\"Model architecture parameters:\")\n",
    "print(f\"  Input dimensions: {n_lags} lags × {n_y} × {n_x} pixels\")\n",
    "print(f\"  Output units: {n_units} neurons\")\n",
    "print(f\"  Temporal channels: {temporal_channels}\")\n",
    "print(f\"  Spatial channels: {res_channels}\")\n",
    "print(f\"  Kernel size: {kernel_size}×{kernel_size}\")\n",
    "print(f\"  Spatial layers: {n_layers}\")\n",
    "\n",
    "# Calculate baseline firing rates for initialization\n",
    "baseline_rates = (gabor_dataset['robs'][gabor_train_inds] * gabor_dataset['dfs'][gabor_train_inds]).sum(0) / gabor_dataset['dfs'][gabor_train_inds].sum(0)\n",
    "print(f\"Baseline firing rates: {baseline_rates.mean():.3f} ± {baseline_rates.std():.3f} spikes/bin\")\n",
    "\n",
    "# Create and test model\n",
    "print(\"\\nCreating ResNet model...\")\n",
    "model = SpatioTemporalResNet(n_lags, n_y, n_x, n_units, temporal_channels, res_channels, kernel_size, n_layers, baseline_rates)\n",
    "\n",
    "print(\"Testing forward pass...\")\n",
    "batch = model(test_batch, debug=True)\n",
    "print(f\"✅ Model forward pass successful!\")\n",
    "print(f\"   Prediction shape: {batch['rhat'].shape}\")\n",
    "print(f\"   Prediction range: {batch['rhat'].min():.3f} - {batch['rhat'].max():.3f}\")\n",
    "\n",
    "print(\"\\nVisualizing initial model weights...\")\n",
    "model.plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c61dab-adfc-431a-b57c-101a23c8091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# ============================================================================\n",
    "# 6. MODEL TRAINING FRAMEWORK\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "This section implements the training pipeline for neural network models.\n",
    "We use Poisson loss (appropriate for spike count data) with data filtering\n",
    "and regularization to prevent overfitting.\n",
    "\n",
    "Key components:\n",
    "1. Masked Poisson loss: Handles variable data quality\n",
    "2. Early stopping: Prevents overfitting\n",
    "3. Regularization: Encourages smooth temporal filters, which may be more biologically plausible\n",
    "\"\"\"\n",
    "\n",
    "def masked_poisson_nll_loss(output, target, dfs=None):\n",
    "    \"\"\"\n",
    "    Compute masked Poisson negative log-likelihood loss.\n",
    "\n",
    "    The Poisson distribution is appropriate for modeling neural spike counts\n",
    "    because spikes are discrete events with a natural rate parameter.\n",
    "\n",
    "    The masking allows us to exclude low-quality time periods from training,\n",
    "    which is crucial when working with real neural data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output : torch.Tensor\n",
    "        Model predictions (firing rates), shape [batch, n_units]\n",
    "    target : torch.Tensor\n",
    "        Target spike counts, shape [batch, n_units]\n",
    "    dfs : torch.Tensor, optional\n",
    "        Quality mask (degrees of freedom), shape [batch, n_units] or [batch, 1]\n",
    "        Values should be 0 (exclude) or 1 (include)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Computed loss (scalar)\n",
    "    \"\"\"\n",
    "    # Compute Poisson NLL for each sample and unit\n",
    "    loss = F.poisson_nll_loss(output, target, log_input=False, full=False, reduction='none')\n",
    "\n",
    "    if dfs is not None:\n",
    "        # Expand mask if needed\n",
    "        if dfs.shape[1] == 1:\n",
    "            dfs = dfs.expand(-1, loss.shape[1])\n",
    "\n",
    "        # Apply quality mask and normalize by valid samples\n",
    "        loss = loss * dfs\n",
    "        loss = loss.sum() / dfs.sum()\n",
    "    else:\n",
    "        # Simple average if no masking\n",
    "        loss = loss.mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4960c5-9235-41b2-91bc-dfc9a7eecf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 6.1 TRAINING FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def train_model(model, train_dataset, val_dataset,\n",
    "                n_epochs=10, lr=3e-3, weight_decay=1e-4,\n",
    "                smoothness_lambda=1e-4, batch_size=256, patience=2,\n",
    "                device='cuda', num_workers=None, plot_weights=True,\n",
    "                verbose=True):\n",
    "    \"\"\"\n",
    "    Train a spatiotemporal CNN model on neural data with comprehensive monitoring.\n",
    "\n",
    "    This function implements best practices for neural network training:\n",
    "    - Early stopping to prevent overfitting\n",
    "    - Learning rate scheduling (via AdamW optimizer)\n",
    "    - Regularization for biologically plausible filters\n",
    "    - Comprehensive metrics tracking (loss and bits per spike)\n",
    "    - Quality masking for real neural data\n",
    "\n",
    "    The \"bits per spike\" metric is particularly important in computational\n",
    "    neuroscience - it measures how much information the model captures\n",
    "    about each spike, with higher values indicating better predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The model to train (SpatioTemporalResNet or SpatioTemporalCNN)\n",
    "    train_dataset : CombinedEmbeddedDataset\n",
    "        Training dataset with stimulus and response data\n",
    "    val_dataset : CombinedEmbeddedDataset\n",
    "        Validation dataset for monitoring overfitting\n",
    "    n_epochs : int, optional\n",
    "        Maximum number of training epochs. Default is 10.\n",
    "    lr : float, optional\n",
    "        Learning rate for AdamW optimizer. Default is 3e-3.\n",
    "    weight_decay : float, optional\n",
    "        L2 regularization strength. Default is 1e-4.\n",
    "    smoothness_lambda : float, optional\n",
    "        Temporal smoothness regularization strength. Default is 1e-4.\n",
    "    batch_size : int, optional\n",
    "        Batch size for training. Default is 256.\n",
    "    patience : int, optional\n",
    "        Early stopping patience (epochs without improvement). Default is 2.\n",
    "    device : str, optional\n",
    "        Device for computation ('cuda' or 'cpu'). Default is 'cuda'.\n",
    "    num_workers : int, optional\n",
    "        Number of workers for data loading. Default is os.cpu_count()//2.\n",
    "    plot_weights : bool, optional\n",
    "        Whether to visualize model weights each epoch. Default is True.\n",
    "    verbose : bool, optional\n",
    "        Whether to print detailed training progress. Default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Comprehensive training results containing:\n",
    "        - 'model': trained model with best validation weights loaded\n",
    "        - 'train_losses': list of training losses per epoch\n",
    "        - 'val_losses': list of validation losses per epoch\n",
    "        - 'train_bps': list of training bits per spike per epoch\n",
    "        - 'val_bps': list of validation bits per spike per epoch\n",
    "        - 'step_losses': list of losses per training step\n",
    "        - 'step_numbers': list of step numbers for plotting\n",
    "        - 'best_epoch': epoch number with best validation performance\n",
    "    \"\"\"\n",
    "    # ========================================================================\n",
    "    # TRAINING SETUP\n",
    "    # ========================================================================\n",
    "\n",
    "    if num_workers is None:\n",
    "        num_workers = os.cpu_count() // 2\n",
    "\n",
    "    # Create data loaders with appropriate settings\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True if device == 'cuda' else False\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True if device == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # Move model to computation device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Setup AdamW optimizer (better than Adam for most cases)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Initialize bits-per-spike aggregator for performance monitoring\n",
    "    bps_agg = PoissonBPSAggregator()\n",
    "\n",
    "    # Initialize metric tracking lists\n",
    "    train_losses = []\n",
    "    train_bps = []\n",
    "    val_losses = []\n",
    "    val_bps = []\n",
    "    step_losses = []\n",
    "    step_numbers = []\n",
    "\n",
    "    # Early stopping variables\n",
    "    best_val_loss = np.inf\n",
    "    best_state = None\n",
    "    patience_count = 0\n",
    "    step = 0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"🚀 Starting training for up to {n_epochs} epochs...\")\n",
    "        print(f\"   Training batches per epoch: {len(train_loader)}\")\n",
    "        print(f\"   Validation batches per epoch: {len(val_loader)}\")\n",
    "        print(f\"   Device: {device}\")\n",
    "        print(f\"   Optimizer: AdamW (lr={lr}, weight_decay={weight_decay})\")\n",
    "        print(f\"   Early stopping patience: {patience} epochs\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # MAIN TRAINING LOOP\n",
    "    # ========================================================================\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"EPOCH {epoch+1}/{n_epochs}\")\n",
    "            print(f\"{'='*60}\")\n",
    "\n",
    "        # Visualize model weights (helpful for debugging)\n",
    "        if plot_weights and hasattr(model, 'plot_weights'):\n",
    "            print(\"📊 Current model weights:\")\n",
    "            model.plot_weights()\n",
    "\n",
    "        # ====================================================================\n",
    "        # TRAINING PHASE\n",
    "        # ====================================================================\n",
    "        model.train()  # Set model to training mode\n",
    "        epoch_train_losses = []\n",
    "        bps_agg.reset()\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f\"🔥 Training\", disable=not verbose)\n",
    "        for batch in train_pbar:\n",
    "            # Move batch to computation device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            batch = model(batch)\n",
    "\n",
    "            # Accumulate predictions for BPS calculation\n",
    "            bps_agg(batch)\n",
    "\n",
    "            # Calculate primary loss (Poisson NLL with quality masking)\n",
    "            loss = masked_poisson_nll_loss(batch['rhat'], batch['robs'], batch['dfs'])\n",
    "\n",
    "            # Add temporal smoothness regularization (encourages smooth filters)\n",
    "            if hasattr(model, 'temporal_smoothness_regularization'):\n",
    "                reg_loss = model.temporal_smoothness_regularization()\n",
    "                loss += smoothness_lambda * reg_loss\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track training progress\n",
    "            step_loss = loss.item()\n",
    "            step_losses.append(step_loss)\n",
    "            step_numbers.append(step)\n",
    "            epoch_train_losses.append(step_loss)\n",
    "\n",
    "            # Update progress bar with current loss\n",
    "            if verbose:\n",
    "                train_pbar.set_postfix({\n",
    "                    'loss': f'{step_loss:.4f}',\n",
    "                    'step': step\n",
    "                })\n",
    "            step += 1\n",
    "\n",
    "        # Calculate epoch-level training metrics\n",
    "        avg_train_loss = np.mean(epoch_train_losses)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_bps.append(bps_agg.closure().cpu().numpy())\n",
    "        bps_agg.reset()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"📈 Training Results:\")\n",
    "            print(f\"   Average Loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"   Average BPS: {train_bps[-1].mean():.4f} ± {train_bps[-1].std():.4f}\")\n",
    "\n",
    "        # ====================================================================\n",
    "        # VALIDATION PHASE\n",
    "        # ====================================================================\n",
    "        model.eval()  # Set model to evaluation mode (disables dropout, etc.)\n",
    "        val_loss_total = 0\n",
    "        val_samples = 0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "            val_pbar = tqdm(val_loader, desc=f\"🔍 Validation\", disable=not verbose)\n",
    "            for batch in val_pbar:\n",
    "                # Move batch to device\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "                # Forward pass (no gradients needed)\n",
    "                batch = model(batch)\n",
    "\n",
    "                # Calculate validation loss\n",
    "                val_loss = masked_poisson_nll_loss(batch['rhat'], batch['robs'], batch['dfs'])\n",
    "\n",
    "                # Accumulate weighted loss (important for proper averaging with masking)\n",
    "                n_samples = batch['dfs'].sum().item()\n",
    "                val_loss_total += val_loss.item() * n_samples\n",
    "                val_samples += n_samples\n",
    "\n",
    "                # Accumulate for BPS calculation\n",
    "                bps_agg(batch)\n",
    "\n",
    "                # Update progress bar\n",
    "                if verbose:\n",
    "                    val_pbar.set_postfix({'loss': f'{val_loss.item():.4f}'})\n",
    "\n",
    "        # Calculate epoch-level validation metrics\n",
    "        avg_val_loss = val_loss_total / val_samples if val_samples > 0 else 0\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Calculate validation BPS\n",
    "        val_bps.append(bps_agg.closure().cpu().numpy())\n",
    "        bps_agg.reset()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"📊 Validation Results:\")\n",
    "            print(f\"   Average Loss: {avg_val_loss:.4f}\")\n",
    "            print(f\"   Average BPS: {val_bps[-1].mean():.4f} ± {val_bps[-1].std():.4f}\")\n",
    "\n",
    "        # ====================================================================\n",
    "        # EARLY STOPPING LOGIC\n",
    "        # ====================================================================\n",
    "\n",
    "        # Check if validation performance improved\n",
    "        if epoch > 0 and val_losses[-1] >= best_val_loss:\n",
    "            patience_count += 1\n",
    "            if verbose:\n",
    "                print(f\"⚠️  No improvement: {val_losses[-2]:.4f} → {val_losses[-1]:.4f}\")\n",
    "                print(f\"   Patience: {patience_count}/{patience}\")\n",
    "\n",
    "            # Stop training if patience exceeded\n",
    "            if patience_count >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"🛑 Early stopping triggered!\")\n",
    "                    print(f\"   No improvement for {patience} consecutive epochs\")\n",
    "                break\n",
    "        else:\n",
    "            # Validation improved - save best model state\n",
    "            best_val_loss = val_losses[-1]\n",
    "            patience_count = 0\n",
    "\n",
    "            if epoch > 0 and verbose:\n",
    "                print(f\"✅ Validation improved: {val_losses[-2]:.4f} → {val_losses[-1]:.4f}\")\n",
    "\n",
    "            # Save the best model weights\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # ========================================================================\n",
    "    # TRAINING COMPLETION AND MODEL RESTORATION\n",
    "    # ========================================================================\n",
    "\n",
    "    # Find the epoch with best validation performance\n",
    "    best_epoch = np.argmin(val_losses)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"🎯 TRAINING COMPLETED!\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total epochs run: {len(val_losses)}\")\n",
    "        print(f\"Best epoch: {best_epoch+1}\")\n",
    "        print(f\"Best validation loss: {val_losses[best_epoch]:.4f}\")\n",
    "        print(f\"Best validation BPS: {val_bps[best_epoch].mean():.4f} ± {val_bps[best_epoch].std():.4f}\")\n",
    "\n",
    "        if patience_count >= patience:\n",
    "            print(f\"Training stopped early due to no improvement\")\n",
    "        else:\n",
    "            print(f\"Training completed all {n_epochs} epochs\")\n",
    "\n",
    "    # Restore the best model weights\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        if verbose:\n",
    "            print(f\"✅ Loaded best model weights from epoch {best_epoch+1}\")\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"⚠️  No best state saved - using final model weights\")\n",
    "\n",
    "    # Return comprehensive training results\n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_bps': train_bps,\n",
    "        'val_bps': val_bps,\n",
    "        'step_losses': step_losses,\n",
    "        'step_numbers': step_numbers,\n",
    "        'best_epoch': best_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc34a9-e4bf-4441-852b-d6087aba4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 6.2 TRAINING VISUALIZATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def plot_training_summary(training_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of training progress.\n",
    "\n",
    "    Shows three key aspects:\n",
    "    1. Step-by-step training loss (shows convergence behavior)\n",
    "    2. Epoch-level train/val loss (shows overfitting)\n",
    "    3. Epoch-level train/val BPS (shows model performance)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    training_results : dict\n",
    "        Results dictionary from train_model function\n",
    "    \"\"\"\n",
    "    # Extract results\n",
    "    train_losses = training_results['train_losses']\n",
    "    val_losses = training_results['val_losses']\n",
    "    train_bps = training_results['train_bps']\n",
    "    val_bps = training_results['val_bps']\n",
    "    step_losses = training_results['step_losses']\n",
    "    step_numbers = training_results['step_numbers']\n",
    "    best_epoch = training_results['best_epoch']\n",
    "\n",
    "    # Create comprehensive plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle('Training Progress Summary', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Plot 1: Training loss per step (shows detailed convergence)\n",
    "    axes[0].plot(step_numbers, step_losses, alpha=0.7, linewidth=0.8, color='steelblue')\n",
    "    axes[0].set_xlabel('Training Step')\n",
    "    axes[0].set_ylabel('Poisson NLL Loss')\n",
    "    axes[0].set_title('Training Loss per Step\\n(Shows convergence behavior)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: Training and validation loss per epoch\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    axes[1].plot(epochs, train_losses, 'b-o', label='Training Loss', markersize=4)\n",
    "    axes[1].plot(epochs, val_losses, 'r-o', label='Validation Loss', markersize=4)\n",
    "    axes[1].axvline(best_epoch + 1, color='green', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch+1})')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Average Poisson NLL Loss')\n",
    "    axes[1].set_title('Training vs Validation Loss\\n(Shows overfitting)')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Plot 3: Training and validation bits per spike\n",
    "    train_bps_mean = np.array([bps.mean() for bps in train_bps])\n",
    "    val_bps_mean = np.array([bps.mean() for bps in val_bps])\n",
    "\n",
    "    axes[2].plot(epochs, train_bps_mean, 'b-o', label='Training BPS', markersize=4)\n",
    "    axes[2].plot(epochs, val_bps_mean, 'r-o', label='Validation BPS', markersize=4)\n",
    "    axes[2].axvline(best_epoch + 1, color='green', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch+1})')\n",
    "    axes[2].axhline(0, color='black', linestyle=':', alpha=0.5, label='Chance Level')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Bits per Spike')\n",
    "    axes[2].set_title('Model Performance (BPS)\\n(Higher is better)')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(f\"\\n📊 Training Summary:\")\n",
    "    print(f\"   Final training BPS: {train_bps_mean[-1]:.4f}\")\n",
    "    print(f\"   Final validation BPS: {val_bps_mean[-1]:.4f}\")\n",
    "    print(f\"   Best validation BPS: {val_bps_mean[best_epoch]:.4f} (epoch {best_epoch+1})\")\n",
    "    print(f\"   Performance gap: {train_bps_mean[-1] - val_bps_mean[-1]:.4f} BPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc59f26-bac7-4515-82a7-b04e50e2550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# ============================================================================\n",
    "# 7. MODEL TRAINING EXPERIMENTS\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Now we train three different models to test our main research question:\n",
    "Do CNN models trained on one visual stimulus generalize to different conditions?\n",
    "\n",
    "We train:\n",
    "1. Gabor-only model: Trained only on Gabor stimuli\n",
    "2. Natural images-only model: Trained only on natural images\n",
    "3. Combined model: Trained on both stimulus types\n",
    "\n",
    "This experimental design allows us to test cross-condition generalization.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813bc0a-c9cc-4e39-b39a-efb6fceca4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 7.1 TRAINING CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Define training hyperparameters\n",
    "training_config = {\n",
    "    'n_epochs': 20,              # Maximum epochs (early stopping may end sooner)\n",
    "    'lr': 1e-3,                  # Learning rate\n",
    "    'weight_decay': 1e-4,        # L2 regularization strength\n",
    "    'smoothness_lambda': 1e-4,   # Temporal smoothness regularization\n",
    "    'batch_size': 256,           # Batch size \n",
    "    'patience': 2,               # Early stopping patience\n",
    "    'device': device,            # Use GPU if available\n",
    "    'plot_weights': False,        # Visualize weights during training\n",
    "    'verbose': True              # Print detailed progress\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1082623-c7cf-4efd-a974-a20fa28ff07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 7.2 EXPERIMENT 1: GABOR-ONLY MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nTraining model on Gabor stimuli only\")\n",
    "print(f\"Training samples: {len(gabor_train_dataset):,}\")\n",
    "print(f\"Validation samples: {len(gabor_val_dataset):,}\")\n",
    "\n",
    "# Create fresh model for Gabor training\n",
    "gabor_model = SpatioTemporalResNet(n_lags, n_y, n_x, n_units, temporal_channels,\n",
    "                                  res_channels, kernel_size, n_layers, baseline_rates)\n",
    "\n",
    "# Train the model\n",
    "gabor_results = train_model(\n",
    "    model=gabor_model,\n",
    "    train_dataset=gabor_train_dataset,\n",
    "    val_dataset=gabor_val_dataset,\n",
    "    **training_config\n",
    ")\n",
    "\n",
    "# Visualize training progress\n",
    "print(\"\\nGabor Model Training Summary:\")\n",
    "plot_training_summary(gabor_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a758a-fb5e-493e-b68c-7c6cbc52e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 7.3 EXPERIMENT 2: NATURAL IMAGES-ONLY MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nTraining model on Natural Images only\")\n",
    "print(f\"Training samples: {len(ni_train_dataset):,}\")\n",
    "print(f\"Validation samples: {len(ni_val_dataset):,}\")\n",
    "\n",
    "# Create fresh model for Natural Images training\n",
    "ni_model = SpatioTemporalResNet(n_lags, n_y, n_x, n_units, temporal_channels,\n",
    "                               res_channels, kernel_size, n_layers, baseline_rates)\n",
    "\n",
    "# Train the model\n",
    "ni_results = train_model(\n",
    "    model=ni_model,\n",
    "    train_dataset=ni_train_dataset,\n",
    "    val_dataset=ni_val_dataset,\n",
    "    **training_config\n",
    ")\n",
    "\n",
    "# Visualize training progress\n",
    "print(\"\\nNatural Images Model Training Summary:\")\n",
    "plot_training_summary(ni_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35562e9-b6af-4821-a63d-a7960288fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 7.4 EXPERIMENT 3: COMBINED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nTraining model on both stimulus types\")\n",
    "print(f\"Training samples: {len(both_train_dataset):,}\")\n",
    "print(f\"Validation samples: {len(both_val_dataset):,}\")\n",
    "\n",
    "# Create fresh model for combined training\n",
    "both_model = SpatioTemporalResNet(n_lags, n_y, n_x, n_units, temporal_channels,\n",
    "                                 res_channels, kernel_size, n_layers, baseline_rates)\n",
    "\n",
    "# Train the model\n",
    "both_results = train_model(\n",
    "    model=both_model,\n",
    "    train_dataset=both_train_dataset,\n",
    "    val_dataset=both_val_dataset,\n",
    "    **training_config\n",
    ")\n",
    "\n",
    "# Visualize training progress\n",
    "print(\"\\nCombined Model Training Summary:\")\n",
    "plot_training_summary(both_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c5b1a-687a-4c02-a4f0-e193389914a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 7.5 COMPARE TRAINED MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔍 COMPARING TRAINED MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extract trained models for easier reference\n",
    "gabor_model = gabor_results['model']\n",
    "ni_model = ni_results['model']\n",
    "both_model = both_results['model']\n",
    "\n",
    "# Compare training performance\n",
    "print(\"Training Performance Summary:\")\n",
    "print(f\"  Gabor model - Final val BPS: {gabor_results['val_bps'][-1].mean():.4f}\")\n",
    "print(f\"  NI model - Final val BPS: {ni_results['val_bps'][-1].mean():.4f}\")\n",
    "print(f\"  Combined model - Final val BPS: {both_results['val_bps'][-1].mean():.4f}\")\n",
    "\n",
    "# Visualize learned features\n",
    "print(\"\\nPlotting learned model weights...\")\n",
    "\n",
    "print(\"\\nGabor Model Weights:\")\n",
    "gabor_model.plot_weights()\n",
    "\n",
    "print(\"\\nNatural Images Model Weights:\")\n",
    "ni_model.plot_weights()\n",
    "\n",
    "print(\"\\nCombined Model Weights:\")\n",
    "both_model.plot_weights()\n",
    "\n",
    "print(\"\\nKey observations to look for:\")\n",
    "print(\"- How do temporal filters differ between models?\")\n",
    "print(\"- Are spatial filters qualitatively different for natural images?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d5f3e-bdab-4222-8876-e3ddab88062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 8. CROSS-CONDITION GENERALIZATION TESTING\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Now we will test how well each model generalizes across stimulus conditions. \n",
    "\n",
    "We evaluate each model on both test sets to measure:\n",
    "1. Within-condition performance (how well models perform on trained stimuli)\n",
    "2. Cross-condition generalization (how well they transfer to out-of-distribution stimuli)\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_model_on_dataset(model, dataset, batch_size=256, device='cuda', desc=\"Evaluating\"):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on a test dataset.\n",
    "\n",
    "    This function computes the bits per spike (BPS) metric, which measures\n",
    "    how well the model predicts neural responses. Higher BPS indicates\n",
    "    better model performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The trained model to evaluate\n",
    "    dataset : CombinedEmbeddedDataset\n",
    "        The test dataset to evaluate on\n",
    "    batch_size : int, optional\n",
    "        Batch size for evaluation. Default is 256.\n",
    "    device : str, optional\n",
    "        Device to run evaluation on. Default is 'cuda'.\n",
    "    desc : str, optional\n",
    "        Description for progress bar. Default is \"Evaluating\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Bits per spike for each unit (shape: [n_units])\n",
    "    \"\"\"\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    bps_aggregator = PoissonBPSAggregator()\n",
    "\n",
    "    # Create data loader (no shuffling needed for evaluation)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=4, pin_memory=True if device == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():  # Disable gradients for efficiency\n",
    "        for batch in tqdm(loader, desc=desc):\n",
    "            # Move batch to device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # Forward pass\n",
    "            batch = model(batch)\n",
    "\n",
    "            # Accumulate predictions for BPS calculation\n",
    "            bps_aggregator(batch)\n",
    "\n",
    "    # Calculate final BPS per unit\n",
    "    bps = bps_aggregator.closure().cpu().numpy()\n",
    "    bps_aggregator.reset()\n",
    "\n",
    "    return bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0befe-2fb3-42bf-a1b7-f29a98fa884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 8.1 COMPREHENSIVE MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nEvaluating all models on both test sets...\")\n",
    "\n",
    "# Dictionary to store all evaluation results\n",
    "evaluation_results = {}\n",
    "\n",
    "# Define models and test datasets\n",
    "model_names = ['Gabor Model', 'NI Model', 'Both Model']\n",
    "models = [gabor_model, ni_model, both_model]\n",
    "test_datasets = {\n",
    "    'Gabor Test': gabor_test_dataset,\n",
    "    'NI Test': ni_test_dataset\n",
    "}\n",
    "\n",
    "print(f\"\\nTest set sizes:\")\n",
    "for name, dataset in test_datasets.items():\n",
    "    print(f\"  {name}: {len(dataset):,} samples\")\n",
    "\n",
    "# Evaluate each model on each test set\n",
    "for model_idx, (model_name, model) in enumerate(zip(model_names, models)):\n",
    "    evaluation_results[model_name] = {}\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "\n",
    "    for test_name, test_dataset in test_datasets.items():\n",
    "        print(f\"   Testing on {test_name}...\")\n",
    "\n",
    "        # Evaluate model performance\n",
    "        bps = evaluate_model_on_dataset(\n",
    "            model, test_dataset,\n",
    "            batch_size=256, device=device,\n",
    "            desc=f\"{model_name} → {test_name}\"\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        evaluation_results[model_name][test_name] = bps\n",
    "\n",
    "        # Print summary statistics\n",
    "        print(f\"     Mean BPS: {bps.mean():.4f} ± {bps.std():.4f}\")\n",
    "        print(f\"     Median BPS: {np.median(bps):.4f}\")\n",
    "        print(f\"     Units with BPS > 0: {np.sum(bps > 0)}/{len(bps)} ({np.sum(bps > 0)/len(bps)*100:.1f}%)\")\n",
    "\n",
    "print(\"Cross-condition evaluation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cb211-f65a-485f-81f0-fab863082c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 8.2 ANALYZE GENERALIZATION PATTERNS\n",
    "# ============================================================================\n",
    "\n",
    "for model_name in model_names:\n",
    "    gabor_bps = evaluation_results[model_name]['Gabor Test'].mean()\n",
    "    ni_bps = evaluation_results[model_name]['NI Test'].mean()\n",
    "\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Gabor Test BPS: {gabor_bps:.4f}\")\n",
    "    print(f\"  NI Test BPS: {ni_bps:.4f}\")\n",
    "\n",
    "    if 'Gabor' in model_name:\n",
    "        print(f\"  Cross-condition drop: {gabor_bps - ni_bps:.4f} BPS\")\n",
    "    elif 'NI' in model_name:\n",
    "        print(f\"  Cross-condition drop: {ni_bps - gabor_bps:.4f} BPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818036ba-00c7-4a55-92b6-eea82c2590b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ============================================================================\n",
    "# 8.3 VISUALIZATION OF RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "def plot_bps_distributions(evaluation_results, min_bps=-10, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize of model performance across conditions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    evaluation_results : dict\n",
    "        Dictionary containing BPS results for each model and test set\n",
    "    min_bps : float, optional\n",
    "        Minimum BPS value to display (clips very negative outliers)\n",
    "    save_path : str, optional\n",
    "        Path to save the plot. If None, plot is displayed.\n",
    "    \"\"\"\n",
    "    # Set up the figure with publication-quality styling\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "    # Colors for different models\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Blue, Orange, Green\n",
    "    model_names = list(evaluation_results.keys())\n",
    "    test_names = ['Gabor Test', 'NI Test']\n",
    "\n",
    "    # Plot box plots with swarm plots for each test set\n",
    "    for test_idx, test_name in enumerate(test_names):\n",
    "        ax = axes[test_idx]\n",
    "\n",
    "        # Prepare data for matplotlib boxplot and seaborn swarmplot\n",
    "        bps_data = [evaluation_results[model_name][test_name] for model_name in model_names]\n",
    "        positions = np.arange(-.4, len(model_names) - .4)\n",
    "        \n",
    "        # Plot matplotlib box plot first (behind)\n",
    "        box_parts = ax.boxplot(bps_data, positions=positions, patch_artist=True, widths=.2)\n",
    "        \n",
    "        for median in box_parts['medians']:\n",
    "            median.set_color('red')\n",
    "            median.set_linewidth(2)\n",
    "            median.set_alpha(0.6)\n",
    "            median.set_zorder(10)\n",
    "        \n",
    "        for whisker in box_parts['whiskers']:\n",
    "            whisker.set_linewidth(2)\n",
    "            whisker.set_alpha(0.6)\n",
    "\n",
    "        # Color the boxes\n",
    "        for patch, color in zip(box_parts['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.6)\n",
    "        \n",
    "        \n",
    "        # Prepare data for seaborn swarmplot\n",
    "\n",
    "        plot_data = []\n",
    "        for model_name in model_names:\n",
    "            bps_values = evaluation_results[model_name][test_name]\n",
    "            for bps in bps_values:\n",
    "                plot_data.append({'Model': model_name, 'BPS': bps})\n",
    "        \n",
    "        plot_df = pd.DataFrame(plot_data)\n",
    "        \n",
    "        # Plot swarm plot on top\n",
    "        # turn off warnings\n",
    "        import warnings\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            sns.swarmplot(data=plot_df, x='Model', y='BPS', palette=colors, ax=ax, size=5)\n",
    "        \n",
    "        ax.axhline(y=0, color='k', linestyle='--', alpha=0.5, label='Chance Level')\n",
    "        if test_idx == 0:\n",
    "            ax.legend()\n",
    "        \n",
    "        ax.set_ylabel('BPS (bits per spike)')\n",
    "        ax.set_title(f'Model Performance on {test_name}')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xlim([-.8, 2.4])\n",
    "        ax.set_xticks(np.arange(-.2, len(model_names) - .2))\n",
    "        ax.set_xticklabels(model_names)\n",
    "        ax.set_xlabel('')\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    y_lims = [ax.get_ylim() for ax in axes]\n",
    "    y_min = min([lim[0] for lim in y_lims])\n",
    "    y_min = max(y_min, min_bps)\n",
    "    y_max = max([lim[1] for lim in y_lims])\n",
    "    for ax in axes:\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "    \n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the key results visualization\n",
    "print(\"\\n📈 Creating results visualization...\")\n",
    "plot_bps_distributions(evaluation_results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
